{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc3e6f2-b7b9-414a-91eb-3b21876fc79b",
   "metadata": {},
   "source": [
    "# 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c447d711-fee6-4d87-adf2-0b276738b7cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1b1ab-4114-450d-b484-48d0865fdcb0",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4dd604-a89a-43b6-af6e-b06507cb6163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/opt/ml'\n",
    "data_path = path +'/data'\n",
    "books_path = data_path + '/books.csv'\n",
    "users_path = data_path + '/users.csv'\n",
    "train_ratings_path = data_path + '/train_ratings.csv'\n",
    "test_ratings_path = data_path + '/test_ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6a76f5-3500-4561-9601-52b2fe1f9955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_books = pd.read_csv(books_path) # book table\n",
    "df_users = pd.read_csv(users_path) # users table\n",
    "df_train_ratings = pd.read_csv(train_ratings_path) # train rating\n",
    "df_test_ratings = pd.read_csv(test_ratings_path) # test_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02e5ba6-4348-464d-bf7c-592b6013ce86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def str_lower(x):\n",
    "    try:\n",
    "        return x.lower()\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19baea41-64fb-4ba6-9abb-7e6af0a75c6a",
   "metadata": {},
   "source": [
    "## 1) Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463177fa-33dd-462f-8baf-c97c14e0fd8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in df_users.columns:\n",
    "    if column == 'user_id':\n",
    "        continue\n",
    "    if df_users[column].dtype == object:\n",
    "        df_users[column] = df_users[column].apply(str_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f9e66-71e1-4c81-9cbc-82c6628d18cd",
   "metadata": {},
   "source": [
    "### 1-1) Location 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00212e57-dda7-477c-a06e-6ad091aaa5c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_users['location'] = df_users['location'].apply(lambda x : re.sub(r'[^a-zA-Z,]', '', x)) # 알파벳을 제외한 특수문자 제거\n",
    "df_users['location'] = df_users['location'].apply(lambda x: ','.join(map(str, ['na' if '' == i else i for i in x.split(',')]))) # 공백은 na로 표시\n",
    "\n",
    "df_users['location_city'] = df_users['location'].apply(lambda x: x.split(',')[0].strip()) # 도시\n",
    "df_users['location_state'] = df_users['location'].apply(lambda x: x.split(',')[1].strip()) # 주\n",
    "df_users['location_country'] = df_users['location'].apply(lambda x: x.split(',')[2].strip()) # 국가\n",
    "\n",
    "df_users = df_users.replace('na', np.nan) # na를 NaN값으로 변환\n",
    "df_users = df_users.replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97fa88b-031e-4332-ac93-c66825b51ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1556/1556 [00:13<00:00, 117.43it/s]\n",
      "100%|██████████| 1556/1556 [00:13<00:00, 116.01it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 90.15it/s] \n",
      "100%|██████████| 25/25 [00:00<00:00, 117.10it/s]\n",
      "100%|██████████| 1172/1172 [00:09<00:00, 117.83it/s]\n",
      "100%|██████████| 1172/1172 [00:10<00:00, 115.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 85.60it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 113.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# state 결측치는 city,country 정보, country 결측치는 city,state 정보 이용해서 해결\n",
    "def fillna_location(to_fill:int,to_use:int):\n",
    "    column_name = {0:'location_city',1:'location_state',2:'location_country'}\n",
    "    to_fill_colname,to_use_colname = column_name[to_fill],column_name[to_use]\n",
    "    \n",
    "    modify_location = set(df_users[(df_users[to_fill_colname].isna()) & ((df_users[to_use_colname].notnull()))][to_use_colname].values)\n",
    "    location_list = []\n",
    "    for location in tqdm(modify_location): \n",
    "        try:\n",
    "            candidates = df_users[(df_users[to_use_colname]==location) & ((df_users[to_use_colname].notnull()))]['location'].value_counts()\n",
    "            first = candidates.idxmax()\n",
    "            for k, v in dict(candidates).items():\n",
    "                k = k.split(',')\n",
    "                if 'na' not in k:\n",
    "                    right_location = ','.join(map(str, k))\n",
    "                    break\n",
    "            else:\n",
    "                right_location = first\n",
    "            location_list.append(right_location)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for location in tqdm(location_list): # [지역, 주, 국가]\n",
    "        df_users.loc[df_users[(df_users[to_use_colname]==location.split(',')[to_use]) & (df_users[to_fill_colname].isna())].index, to_fill_colname] = location.split(',')[to_fill]\n",
    "\n",
    "fillna_location(1,0) # state의 결측치를 city의 정보를 활용해 채워보자\n",
    "fillna_location(1,2) # state의 결측치를 country의 정보를 활용해 채워보자\n",
    "fillna_location(2,0) # country의 결측치를 city의 정보를 활용해 채워보자\n",
    "fillna_location(2,1) # country의 결측치를 state의 정보를 활용해 채워보자\n",
    "\n",
    "\n",
    "# 남은 결측치는 unknown으로 채우기\n",
    "df_users[['location_city', 'location_state', 'location_country']] = df_users[['location_city', 'location_state', 'location_country']].fillna('unknown')\n",
    "\n",
    "# where가 들어간 city, state, country는 다 unknown으로 교체\n",
    "df_users.loc[df_users[df_users['location_city'].str.contains('where')].index, 'location_city'] = 'unknown'\n",
    "df_users.loc[df_users[df_users['location_state'].str.contains('where')].index, 'location_state'] = 'unknown'\n",
    "df_users.loc[df_users[df_users['location_country'].str.contains('where')].index, 'location_country'] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92826004-f37c-4eb8-8c95-56e86051f3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = df_users.groupby('location_city')['location_country'].value_counts().groupby('location_city').idxmax().apply(lambda x : x[-1]).reset_index().rename(columns = {'count':'location_country'})\n",
    "city2country = dict(zip(temp['location_city'].values, temp['location_country'].values))\n",
    "\n",
    "df_users['location_country'] = df_users['location_city'].map(city2country) #location city에 대해 Location_country가 max인 나라로 채워서 noise 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4fdf9fd-c453-4ab0-b0b4-fd70ab77028d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_users = df_users.drop('location', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687d166-2ea9-4880-976a-1643a15f87dc",
   "metadata": {},
   "source": [
    "### 1-2) age 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23920503-b561-4ef7-84da-4ae37d65a34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binning_age(x):\n",
    "    if np.isnan(x):\n",
    "        return np.nan\n",
    "    elif x < 20:\n",
    "        x = 10\n",
    "    elif 20 <= x < 30:\n",
    "        x = 20\n",
    "    elif 30 <= x < 40:\n",
    "        x = 30\n",
    "    elif 40 <= x < 50:\n",
    "        x = 40\n",
    "    elif 50 <= x < 60:\n",
    "        x = 60 \n",
    "    elif x >= 60:\n",
    "        x = 60\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7bd72a-19bb-43b5-9b57-17036bb80958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 인덱싱 처리된 데이터 조인\n",
    "train_df = df_train_ratings.merge(df_users, on='user_id', how='left').merge(df_books[['isbn', 'category', 'publisher', 'language', 'book_author', 'year_of_publication']], on='isbn', how='left')\n",
    "test_df = df_test_ratings.merge(df_users, on='user_id', how='left').merge(df_books[['isbn', 'category', 'publisher', 'language', 'book_author', 'year_of_publication']], on='isbn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3576c4ca-45f4-42b4-bd89-cd85849adc2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92662/92662 [00:04<00:00, 22383.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. 편차의 평균이 적은 column 두 개를 활용해 결측치 채우기\n",
    "# 'book_author'와 'location_city'를 기준으로 train_df의 'age' 컬럼의 평균을 계산\n",
    "age_means = train_df.groupby([\"book_author\", \"location_city\"])['age'].mean()\n",
    "\n",
    "# train_df의 'age' 컬럼에서 결측치를 가진 행의 인덱스를 가져오기\n",
    "null_age_idx = train_df[train_df['age'].isnull()].index\n",
    "\n",
    "# 결측치를 채울 값들을 저장할 리스트\n",
    "age_fill_values = []\n",
    "\n",
    "for idx in tqdm(null_age_idx):\n",
    "    author = train_df.loc[idx, 'book_author']\n",
    "    city = train_df.loc[idx, 'location_city']\n",
    "    # 'book_author'와 'location_city'가 일치하는 데이터의 평균값으로 결측치를 채우기.\n",
    "    fill_value = age_means[author, city]\n",
    "    age_fill_values.append(fill_value)\n",
    "\n",
    "# 결측치를 채운 값들로 'age' 컬럼을 업데이트.\n",
    "train_df.loc[null_age_idx, 'age'] = age_fill_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dfc36c8-1b9e-4b8b-bf3e-8f6f62dbd88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. 도시의 평균으로 결측치 채우기\n",
    "# 'location_city'를 기준으로 train_df의 'age' 컬럼의 평균을 계산\n",
    "age_means_by_city = train_df.groupby('location_city')['age'].mean()\n",
    "\n",
    "# 'age' 컬럼에서 결측치를 가진 행들의 'location_city' 값을 가져옵니다.\n",
    "null_age_cities = train_df.loc[train_df['age'].isnull(), 'location_city']\n",
    "\n",
    "# 'location_city'에 대한 평균값으로 결측치를 채웁니다.\n",
    "train_df['age'].fillna(value=null_age_cities.map(age_means_by_city), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3b788c5-3e07-4849-a94a-1bf643688326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. 전체 평균으로 결측치 채우기\n",
    "train_df['age'] = train_df['age'].fillna(train_df['age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a3c0c8f-35ec-477e-9307-2bad9fa67995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['binning_age'] = train_df['age'].apply(binning_age)\n",
    "train_df['binning_age'] = train_df['binning_age'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7e7db7b-a793-4442-b9ba-174d9a05edc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop('age', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60835aa8-2ad5-47e4-b485-31ed6ce9251a",
   "metadata": {},
   "source": [
    "## 2) Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57af817c-b517-466b-8b56-c4fa2185bc76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in train_df.columns:\n",
    "    if column == 'isbn':\n",
    "        continue\n",
    "    if train_df[column].dtype == object:\n",
    "        # print(column)\n",
    "        train_df[column] = train_df[column].apply(str_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629fd830-15da-4c7f-85c9-d219d5e2b828",
   "metadata": {},
   "source": [
    "### 2-1) Publisher Number(pnumber) feature 새로 생성 : isbn 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6bcbeb9-fd4b-4e9a-bc03-3aa50e259e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['pnumber'] = train_df['isbn'].apply(lambda x : x[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7432de4-e196-45ec-86c9-738312b65aba",
   "metadata": {},
   "source": [
    "### 2-2) category 결측치 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "824b943f-aeb6-4ce1-9d97-97bb4682844c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# book author 이용해서 해결 (같은 작가가 쓴 카테고리는 동일할 것으로 예상)\n",
    "train_df.loc[train_df[train_df['category'].notnull()].index, 'category'] = train_df[train_df['category'].notnull()]['category'].apply(lambda x: re.sub('[\\W_]+',' ',x).lower().strip())\n",
    "\n",
    "temp = train_df.groupby('book_author')['category'].value_counts().groupby('book_author').idxmax().apply(lambda x : x[-1])\n",
    "temp = defaultdict(lambda : np.nan, temp.to_dict())\n",
    "\n",
    "feature2index = dict(zip(train_df.columns, range(len(train_df.columns))))\n",
    "train_df['category'] = train_df.apply(lambda x : temp[x[feature2index['book_author']]] if type(x[feature2index['category']]) == float and np.isnan(x[feature2index['category']]) else x[feature2index['category']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc0dc8d7-9367-4c55-82cb-cb8b3930fdf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pnumber 이용해서 해결 (같은 출판사에서 나온 카테고리는 동일할 것으로 예상)\n",
    "temp = train_df.groupby('pnumber')['category'].value_counts().groupby('pnumber').idxmax().apply(lambda x : x[-1])\n",
    "temp = defaultdict(lambda : np.nan, temp.to_dict())\n",
    "\n",
    "feature2index = dict(zip(train_df.columns, range(len(train_df.columns))))\n",
    "train_df['category'] = train_df.apply(lambda x : temp[x[feature2index['pnumber']]] if type(x[feature2index['category']]) == float and np.isnan(x[feature2index['category']]) else x[feature2index['category']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b95a462-b7bd-409d-af9e-1b92ccf7a4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# category가 한 단어로 기재된 경우로 통일\n",
    "words = defaultdict(int)\n",
    "for value in train_df['category'].values:\n",
    "    try:\n",
    "        if len(value.split()) == 1: # category가 한 단어로 기재된 경우\n",
    "            words[value] += 1\n",
    "    except:\n",
    "        pass\n",
    "categories = [(value, key) for key,value in words.items()] # category가 한 단어로 기재된 case마다 몇번 등장했는지\n",
    "categories.sort(reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07b40d06-cca4-423e-8541-eca6e292923f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1174/1174 [02:16<00:00,  8.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, category in tqdm(categories):\n",
    "    train_df.loc[train_df[train_df['category'].str.contains(category,na=False)].index,'category_high'] = category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fdcd76-1736-48ff-9fdb-fc81f5e827b7",
   "metadata": {},
   "source": [
    "### 2-3) language 결측치 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50686fa7-0131-4068-90d7-352accc627cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 국가코드를 하나로 엮은 것에서 가장 많이 나온 MAXIMUM 언어로 결측치 해결\n",
    "def country_code(isbn:str):\n",
    "    prefix_1 = ('0','1','2','3','4','5','7')\n",
    "    prefix_2 = tuple(map(str,range(80,94)))\n",
    "    prefix_3 = tuple(list(map(str,range(950,960)))+list(map(str,range(961,969)))+list(map(str,range(970,985)))+['986','987'])\n",
    "    if isbn.startswith(prefix_1):\n",
    "        return isbn[0]\n",
    "    elif isbn.startswith(prefix_2):\n",
    "        return isbn[:2]\n",
    "    elif isbn.startswith(prefix_3):\n",
    "        return isbn[:3]\n",
    "    else:\n",
    "        return np.NaN\n",
    "    \n",
    "train_df['country_code'] = train_df['isbn'].map(country_code)\n",
    "# 각 country에서 가장 많이 이용하는 language를 담은 dict 생성\n",
    "top_languages = {}\n",
    "for country_code, group in train_df.groupby('country_code'):\n",
    "    try:\n",
    "        top_language = group['language'].value_counts().idxmax()\n",
    "        top_languages[country_code] = top_language\n",
    "    except:\n",
    "        pass\n",
    "train_df['most_used_language'] = train_df['country_code'].map(top_languages)\n",
    "# 해당 dict 이용해서 language 결측치 해결\n",
    "train_df.loc[train_df[train_df['language'].isnull()].index,'language'] = train_df.loc[train_df[train_df['language'].isnull()].index,'most_used_language']\n",
    "train_df = train_df.drop(['country_code','most_used_language'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1a94815-f851-4ec1-a40b-c829136bc1bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# book author 이용해서 해결(같은 작가는 동일한 언어의 책을 낼 것으로 예상)\n",
    "temp = train_df.groupby('book_author')['language'].value_counts().groupby('book_author').idxmax().apply(lambda x : x[-1])\n",
    "temp = defaultdict(lambda : np.nan, temp.to_dict())\n",
    "\n",
    "feature2index = dict(zip(train_df.columns, range(len(train_df.columns))))\n",
    "train_df['language'] = train_df.apply(lambda x : temp[x[feature2index['book_author']]] if type(x[feature2index['book_author']]) == float and np.isnan(x[feature2index['language']]) else x[feature2index['language']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f11c51f6-2e58-49d7-99c5-f27e0aeabb4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pnumber 이용해서 해결(같은 출판사는 동일한 언어의 책을 낼 것으로 예상)\n",
    "temp = train_df.groupby('pnumber')['language'].value_counts().groupby('pnumber').idxmax().apply(lambda x : x[-1])\n",
    "temp = defaultdict(lambda : np.nan, temp.to_dict())\n",
    "\n",
    "feature2index = dict(zip(train_df.columns, range(len(train_df.columns))))\n",
    "train_df['language'] = train_df.apply(lambda x : temp[x[feature2index['pnumber']]] if type(x[feature2index['language']]) == float and np.isnan(x[feature2index['language']]) else x[feature2index['language']], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64700770-7dcf-4974-91c8-9d8308d25b0e",
   "metadata": {},
   "source": [
    "### 2-4) year_of_publication binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77f67999-d8cb-4dbc-a473-a16ad1e36b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binning_year(x):\n",
    "    if x < 1970:\n",
    "        return '1970'\n",
    "    elif 1970 <= x < 1980:\n",
    "        return '1980'\n",
    "    elif 1980 <= x < 1990:\n",
    "        return '1990'\n",
    "    elif 1990 <= x < 2000:\n",
    "        return '2000'\n",
    "    else:\n",
    "        return 'Early'\n",
    "    \n",
    "train_df['binning_year'] = train_df['year_of_publication'].apply(binning_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faf6a68-c85b-466a-b15c-1f00c18ca799",
   "metadata": {},
   "source": [
    "### 2-5) book_author cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8029b410-3da8-4c2f-9822-dd0d6703f56a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['book_author'].fillna('unknown',inplace=True)\n",
    "train_df['book_author'] = train_df['book_author'].apply(lambda x : re.sub(r'[^a-zA-Z0-9]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d73854d-e22d-4604-a810-61bd4c3508c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['year_of_publication','publisher','category'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88949f6d-9683-4a98-86bf-e962183961c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in train_df.columns:\n",
    "    train_df[column] = train_df[column].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68a987f4-46e5-4a9a-8754-5bee0d290360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 306795 entries, 0 to 306794\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   user_id           306795 non-null  int64 \n",
      " 1   isbn              306795 non-null  object\n",
      " 2   rating            306795 non-null  int64 \n",
      " 3   location_city     306795 non-null  object\n",
      " 4   location_state    306795 non-null  object\n",
      " 5   location_country  306795 non-null  object\n",
      " 6   language          306795 non-null  object\n",
      " 7   book_author       306795 non-null  object\n",
      " 8   binning_age       306795 non-null  object\n",
      " 9   pnumber           306795 non-null  object\n",
      " 10  category_high     306795 non-null  object\n",
      " 11  binning_year      306795 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 30.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be3cbe2-fb23-4ef2-b978-6b483bb21b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
